{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating the Blind Set\n",
    "\n",
    "* Also known as **holdout dataset**\n",
    "\n",
    "* Cross-validation is not sufficient tot estimate unbiased generalization performance.\n",
    "    - Model hyper-parameters are still optimized on the training set through cross-valiation and grid-search\n",
    "    - This may lead to some degree of overfitting on training data\n",
    "    - Using a blind set helps us to generate a 'never-seen-before condition'\n",
    "    \n",
    "## Generation Criteria:\n",
    "\n",
    "* Structures deposited **after** January 2015\n",
    "     - Release year of JPred4 is 2014\n",
    "* X-ray crystals with resolution < 2,5 $\\overset{\\circ}{A}$\n",
    "* Chain lenght in the range of 50 - 300 residues\n",
    "* Advanced search -> Entry Polymer Types:\n",
    "    - Protein OR Protein/NA \n",
    "* All pairs of sequences within the blind set should share less than 30% sequence identity ('internal redundancy'):\n",
    "- By using ```blastclust``` we can reduce the redundancy\n",
    "\n",
    "* When comparing sequences of the blindset with the JPRED set: All pairs (blind - Jpred) have an less than 30% identity  ('external redundancy')\n",
    "- This will be ensured using ```blastp```\n",
    "\n",
    "* The final blind set will comprise 150 proteins which will be randomly selected among those that meet the above criteria\n",
    "\n",
    "### 1. Downloading Data from the PDB\n",
    "\n",
    "Checked the boxes \"Entry ID\",\"Sequence\",\"Entity Polymer Type\",\"Chain ID\",\"Entry Id (Polymer Entity Identifiers)\".\n",
    "\n",
    "[here the link to my search](https://www.rcsb.org/search?request=%7B%22query%22%3A%7B%22type%22%3A%22group%22%2C%22logical_operator%22%3A%22and%22%2C%22nodes%22%3A%5B%7B%22type%22%3A%22group%22%2C%22logical_operator%22%3A%22and%22%2C%22nodes%22%3A%5B%7B%22type%22%3A%22group%22%2C%22logical_operator%22%3A%22and%22%2C%22nodes%22%3A%5B%7B%22type%22%3A%22terminal%22%2C%22service%22%3A%22text%22%2C%22parameters%22%3A%7B%22operator%22%3A%22greater%22%2C%22negation%22%3Afalse%2C%22value%22%3A%222015-01-31T00%3A00%3A00Z%22%2C%22attribute%22%3A%22rcsb_accession_info.deposit_date%22%7D%2C%22node_id%22%3A0%7D%2C%7B%22type%22%3A%22terminal%22%2C%22service%22%3A%22text%22%2C%22parameters%22%3A%7B%22operator%22%3A%22exact_match%22%2C%22negation%22%3Afalse%2C%22value%22%3A%22X-RAY%20DIFFRACTION%22%2C%22attribute%22%3A%22exptl.method%22%7D%2C%22node_id%22%3A1%7D%2C%7B%22type%22%3A%22terminal%22%2C%22service%22%3A%22text%22%2C%22parameters%22%3A%7B%22operator%22%3A%22less_or_equal%22%2C%22negation%22%3Afalse%2C%22value%22%3A2.5%2C%22attribute%22%3A%22rcsb_entry_info.resolution_combined%22%7D%2C%22node_id%22%3A2%7D%2C%7B%22type%22%3A%22group%22%2C%22logical_operator%22%3A%22or%22%2C%22nodes%22%3A%5B%7B%22type%22%3A%22terminal%22%2C%22service%22%3A%22text%22%2C%22parameters%22%3A%7B%22operator%22%3A%22exact_match%22%2C%22negation%22%3Afalse%2C%22value%22%3A%22Protein%20(only)%22%2C%22attribute%22%3A%22rcsb_entry_info.selected_polymer_entity_types%22%7D%2C%22node_id%22%3A3%7D%2C%7B%22type%22%3A%22terminal%22%2C%22service%22%3A%22text%22%2C%22parameters%22%3A%7B%22operator%22%3A%22exact_match%22%2C%22negation%22%3Afalse%2C%22value%22%3A%22Protein%2FNA%22%2C%22attribute%22%3A%22rcsb_entry_info.selected_polymer_entity_types%22%7D%2C%22node_id%22%3A4%7D%5D%7D%2C%7B%22type%22%3A%22terminal%22%2C%22service%22%3A%22text%22%2C%22parameters%22%3A%7B%22operator%22%3A%22range_closed%22%2C%22negation%22%3Afalse%2C%22value%22%3A%5B50%2C300%5D%2C%22attribute%22%3A%22entity_poly.rcsb_sample_sequence_length%22%7D%2C%22node_id%22%3A5%7D%5D%7D%5D%2C%22label%22%3A%22text%22%7D%5D%2C%22label%22%3A%22query-builder%22%7D%2C%22return_type%22%3A%22entry%22%2C%22request_options%22%3A%7B%22pager%22%3A%7B%22start%22%3A0%2C%22rows%22%3A100%7D%2C%22scoring_strategy%22%3A%22combined%22%2C%22sort%22%3A%5B%7B%22sort_by%22%3A%22score%22%2C%22direction%22%3A%22desc%22%7D%5D%7D%2C%22request_info%22%3A%7B%22src%22%3A%22ui%22%2C%22query_id%22%3A%22dc19df09287d4c5a80018000a03e2a6d%22%7D%7D)\n",
    "\n",
    "* Downloaded as CSV \n",
    "\n",
    "For some reason it automatically adds \"Entry ID\" as column 1. Whenever there is another chain of the same ID the first line of col 1 will be empty --> removed it using awk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Entry ID\",\"Sequence\",\"Entity Polymer Type\",\"Chain ID\",\"Entry Id (Polymer Entity Identifiers)\",\n",
      "\"5EV3\",\"GSQMTRQARRLYVGNIPFGITEEAMMDFFNAQMRLGGLTQAPGNPVLAVQINQDKNFAFLEFRSVDETTQAMAFDGIIFQGQSLKIRRPHDYQPLPGMSENPSVYVPGVVSTVVPDSAHKLFIGGLPNYLNDDQVKELLTSFGPLKAFNLVKDSATGLSKGYAFCEYVDINVTDQAIAGLNGMQLGDKKLLVQRASVGAKN\",\"Protein\",\"A\",\"5EV3\",\n",
      ",\"UUUUUUUU\",\"NA-hybrid\",\"B\",\"5EV3\",\n",
      "\"5EV2\",\"GSQMTRQARRLYVGNIPFGITEEAMMDFFNAQMRLGGLTQAPGNPVLAVQINQDKNFAFLEFRSVDETTQAMAFDGIIFQGQSLKIRRPHDYQPLPGMSENPSVYVPGVVSTVVPDSAHKLFIGGLPNYLNDDQVKELLTSFGPLKAFNLVKDSATGLSKGYAFCEYVDINVTDQAIAGLNGMQLGDKKLLVQRASVGAKN\",\"Protein\",\"A\",\"5EV2\",\n",
      ",\"UUUUUUUU\",\"NA-hybrid\",\"B\",\"5EV2\",\n",
      "\"5EV4\",\"GSQMTRQARRLYVGNIPFGITEEAMMDFFNAQMRLGGLTQAPGNPVLAVQINQDKNFAFLEFRSVDETTQAMAFDGIIFQGQSLKIRRPHDYQPLPGMSENPSVYVPGVVSTVVPDSAHKLFIGGLPNYLNDDQVKELLTSFGPLKAFNLVKDSATGLSKGYAFCEYVDINVTDQAIAGLNGMQLGDKKLLVQRASVGAKN\",\"Protein\",\"A\",\"5EV4\",\n"
     ]
    }
   ],
   "source": [
    "head -6 1.csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in {1..5}\n",
    "do\n",
    "    cat ${i}.csv | awk '{sub(/[^,]*/,\"\");sub(/,/,\"\")} 1' > ${i}new.csv \n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Sequence\",\"Entity Polymer Type\",\"Chain ID\",\"Entry Id (Polymer Entity Identifiers)\",\n",
      "\"MALVDGFLELERSSGKLEWSAILQKMASDLGFSKILFGLLPKDSQDYENAFIVGNYPAAWREHYDRAGYARVDPTVSHCTQSVLPIFWEPSIYQTRKQHEFFEEASAAGLVYGLTMPLHGARGELGALSLSVEAENRAEANRFMESVLPTLWMLKDYALQSGAGLAFEHPVSKPVVLTSREKEVLQWCAIGKTSWEISVICNCSEANVNFHMGNIRRKFGVTSRRVAAIMAVNLGLITL\",\"Protein\",\"A, B\",\"6MWL\",\n",
      "\"SVAHGLAWSYYIGYLRLILPELQARIRTYNQHYNNLLRGAVSQRLYILLPLDCGVPDNLSMADPNIRFLDKLPQQTADRAGIKDRVYSNSIYELLENGQRAGTCVLEYATPLQTLFAMSQYSQAGFSREDRLEQAKLFCQTLEDILADAPESQNNCRLIAYQEPADDSSFSLSQEVLRHLRQEEKEEV\",\"Protein\",\"A, B\",\"6MX0\",\n",
      "\"MKLVWTLSSWDDYEFWQRTDARMVEKINDLIRNAKRTPFAGLGKPEPLKGDMAGYWSRRITAEHRFVYRVSGSGSEQRLEVIQCRFHYQLEVLFQ\",\"Protein\",\"A, B\",\"6N90\",\n",
      "\"MDYKDDDDKGSLVPRGSHMYLRITNIVESSFFTKFIIYLIVLNGITMGLETSKTFMQSFGVYTTLFNQIVITIFTIEIILRIYVHRISFFKDPWSLFDFFVVAISLVPTSSGFEILRVLRVLRLFRLVTAVPQMRKIVSALISVIPGMLSVIALMTLFFYIFAIMATQLFGERFPEWFGTLGESFYTLFQVMTLESWSMGIVRPLMEVYPYAWVFFIPFIFVVTFVMINLVVAIIVDAMAILNQKEEQHIIDEVQSH\",\"Protein\",\"B\",\"6MWA\",\n"
     ]
    }
   ],
   "source": [
    "head -5 4new.csv #now it looks like this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Parsing and Filtering\n",
    "\n",
    "First I need to be aware that some of the chains are nucleic acids (\"NA-hybrid\").\n",
    "\n",
    "Remove all lines containing\n",
    "*  \"NA-hybrid\" \n",
    "*  \"DNA\"\n",
    "*  \"RNA\"\n",
    "\n",
    "to obtain protein sequences only!\n",
    "\n",
    "```  sed -n '/Protein/p' ./filename \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing all lines that do NOT contain \"Protein\" --> this removes the header too!\n",
    "head -1 1new.csv > aa_only.csv # Adding correct header to top of file that will be appended all \"Protein\" lines\n",
    "\n",
    "for i in {1..5} # Appending only lines containing word \"Protein\"\n",
    "do\n",
    "    sed -n '/Protein/p' ${i}new.csv >> aa_only.csv \n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Sequence\",\"Entity Polymer Type\",\"Chain ID\",\"Entry Id (Polymer Entity Identifiers)\",\n",
      "\"GSQMTRQARRLYVGNIPFGITEEAMMDFFNAQMRLGGLTQAPGNPVLAVQINQDKNFAFLEFRSVDETTQAMAFDGIIFQGQSLKIRRPHDYQPLPGMSENPSVYVPGVVSTVVPDSAHKLFIGGLPNYLNDDQVKELLTSFGPLKAFNLVKDSATGLSKGYAFCEYVDINVTDQAIAGLNGMQLGDKKLLVQRASVGAKN\",\"Protein\",\"A\",\"5EV3\",\n",
      "\"GSQMTRQARRLYVGNIPFGITEEAMMDFFNAQMRLGGLTQAPGNPVLAVQINQDKNFAFLEFRSVDETTQAMAFDGIIFQGQSLKIRRPHDYQPLPGMSENPSVYVPGVVSTVVPDSAHKLFIGGLPNYLNDDQVKELLTSFGPLKAFNLVKDSATGLSKGYAFCEYVDINVTDQAIAGLNGMQLGDKKLLVQRASVGAKN\",\"Protein\",\"A\",\"5EV2\",\n",
      "\"GSQMTRQARRLYVGNIPFGITEEAMMDFFNAQMRLGGLTQAPGNPVLAVQINQDKNFAFLEFRSVDETTQAMAFDGIIFQGQSLKIRRPHDYQPLPGMSENPSVYVPGVVSTVVPDSAHKLFIGGLPNYLNDDQVKELLTSFGPLKAFNLVKDSATGLSKGYAFCEYVDINVTDQAIAGLNGMQLGDKKLLVQRASVGAKN\",\"Protein\",\"A\",\"5EV4\",\n",
      "\"SLRSDLINALYDENQKYDVCGIISAEGKIYPLGSDTKVLSTIFELFSRPIINKIAEKHGYIVEEPKQQNHYPDFTLYKPSEPNKKIAIDIKTTYTNKENEKIKFTLGGYTSFIRNNTKNIVYPFDQYIAHWIIGYVYTRVATRKSSLKTYNINELNEIPKPYKGVKVFLQDKWVIAGDLAGSGNTTNIGSIHAHYKDFVEGKGIFDSEDEFLDYWRNYERTSQLRNDKYNNISEYRNWIYRGRK\",\"Protein\",\"A, B\",\"5F8A\",\n",
      "\"MAVLAESELGSEAQRERRKRILDATMAIASKGGYEAVQMRAVADRADVAVGTLYRYFPSKVHLLVSALGREFSRIDAKTDRSAVAGATPFQRLNFMVGKLNRAMQRNPLLTEAMTRAYVFADASAASEVDQVEKLIDSMFARAMANGEPTEDQYHIARVISDVWLSNLLAWLTRRASATDVSKRLDLAVRLLIGDQDSAHHHHHH\",\"Protein\",\"A, B\",\"5FMP\",\n",
      "\"GAASMDKKYSIGLAIGTNSVGWAVITDEYKVPSKKFKVLGNTDRHSIKKNLIGALLFDSGETAEATRLKRTARRRYTRRKNRICYLQEIFSNEMAKVDDSFFHRLEESFLVEEDKKHERHPIFGNIVDEVAYHEKYPTIYHLRKKLVDSTDKADLRLIYLALAHMIKFRGHFLIEGDLNPDNSDVDKLFIQLVQTYNQLFEENPINASGVDAKAILSARLSKSRRLENLIAQLPGEKKNGLFGNLIALSLGLTPNFKSNFDLAEDAKLQLSKDTYDDDLDNLLAQIGDQYADLFLAAKNLSDAILLSDILRVNTEITKAPLSASMIKRYDEHHQDLTLLKALVRQQLPEKYKEIFFDQSKNGYAGYIDGGASQEEFYKFIKPILEKMDGTEELLVKLNREDLLRKQRTFDNGSIPHQIHLGELHAILRRQEDFYPFLKDNREKIEKILTFRIPYYVGPLARGNSRFAWMTRKSEETITPWNFEEVVDKGASAQSFIERMTNFDKNLPNEKVLPKHSLLYEYFTVYNELTKVKYVTEGMRKPAFLSGEQKKAIVDLLFKTNRKVTVKQLKEDYFKKIECFDSVEISGVEDRFNASLGTYHDLLKIIKDKDFLDNEENEDILEDIVLTLTLFEDREMIEERLKTYAHLFDDKVMKQLKRRRYTGWGRLSRKLINGIRDKQSGKTILDFLKSDGFANRNFMQLIHDDSLTFKEDIQKAQVSGQGDSLHEHIANLAGSPAIKKGILQTVKVVDELVKVMGRHKPENIVIEMARENQTTQKGQKNSRERMKRIEEGIKELGSQILKEHPVENTQLQNEKLYLYYLQNGRDMYVDQELDINRLSDYDVDAIVPQSFLKDDSIDNKVLTRSDKNRGKSDNVPSEEVVKKMKNYWRQLLNAKLITQRKFDNLTKAERGGLSELDKAGFIKRQLVETRQITKHVAQILDSRMNTKYDENDKLIREVKVITLKSKLVSDFRKDFQFYKVREINNYHHAHDAYLNAVVGTALIKKYPKLESEFVYGDYKVYDVRKMIAKSEQEIGKATAKYFFYSNIMNFFKTEITLANGEIRKRPLIETNGETGEIVWDKGRDFATVRKVLSMPQVNIVKKTEVQTGGFSKESILPKRNSDKLIARKKDWDPKKYGGFDSPTVAYSVLVVAKVEKGKSKKLKSVKELLGITIMERSSFEKNPIDFLEAKGYKEVKKDLIIKLPKYSLFELENGRKRMLASAGELQKGNELALPSKYVNFLYLASHYEKLKGSPEDNEQKQLFVEQHKHYLDEIIEQISEFSKRVILADANLDKVLSAYNKHRDKPIREQAENIIHLFTLTNLGAPAAFKYFDTTIDRKRYTSTKEVLDATLIHQSITGLYETRIDLSQLGGD\",\"Protein\",\"B\",\"5FQ5\",\n",
      "\"MAPKCIECHINIEMDPVLHDVFKLQVCKQCSKEHPEKYALLTKTECKEDYFLTDPELNDEDLFHRLEKPNPHSGTFARMQLFVRCEVEAFAFKKWGGEEGLDEEWQRREEGKAHRREKKYGSAWSHPQFEK\",\"Protein\",\"A, B\",\"5G32\",\n",
      "\"MAPKCIECHINIEMDPVLHDVFKLQVCKQCSKEHPEKYALLTKTECKEDYFLTDPELNDEDLFHRLEKPNPHSGTFARMQLFVRCEVEAFAFKKWGGEEGLDEEWQRREEGKAHRREKKYGSAWSHPQFEK\",\"Protein\",\"A, B\",\"5G34\",\n",
      "\"MAPKCIECHINIEMDPVLHDVFKLQVCKQCSKEHPEKYALLTKTECKEDYFLTDPELNDEDLFHRLEKPNPHSGTFARMQLFVRCEVEAFAFKKWGGEEGLDEEWQRREEGKAHRREKKYGSAWSHPQFEK\",\"Protein\",\"A, B\",\"5G33\",\n"
     ]
    }
   ],
   "source": [
    "head aa_only.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   29638\n"
     ]
    }
   ],
   "source": [
    "grep \"Protein\" aa_only.csv | wc -l #  29638 Protein chains in the set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Switched to python 3 kernel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading relevant packages:\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "# sns.set() #do we really need that\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sequence</th>\n",
       "      <th>Entity Polymer Type</th>\n",
       "      <th>Chain ID</th>\n",
       "      <th>Entry Id (Polymer Entity Identifiers)</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GSQMTRQARRLYVGNIPFGITEEAMMDFFNAQMRLGGLTQAPGNPV...</td>\n",
       "      <td>Protein</td>\n",
       "      <td>A</td>\n",
       "      <td>5EV3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GSQMTRQARRLYVGNIPFGITEEAMMDFFNAQMRLGGLTQAPGNPV...</td>\n",
       "      <td>Protein</td>\n",
       "      <td>A</td>\n",
       "      <td>5EV2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GSQMTRQARRLYVGNIPFGITEEAMMDFFNAQMRLGGLTQAPGNPV...</td>\n",
       "      <td>Protein</td>\n",
       "      <td>A</td>\n",
       "      <td>5EV4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SLRSDLINALYDENQKYDVCGIISAEGKIYPLGSDTKVLSTIFELF...</td>\n",
       "      <td>Protein</td>\n",
       "      <td>A, B</td>\n",
       "      <td>5F8A</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MAVLAESELGSEAQRERRKRILDATMAIASKGGYEAVQMRAVADRA...</td>\n",
       "      <td>Protein</td>\n",
       "      <td>A, B</td>\n",
       "      <td>5FMP</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29633</th>\n",
       "      <td>DVLMTQIPLSLPVSLGDQASISCRSSQNIVHSNGNTYLEWYLQKPG...</td>\n",
       "      <td>Protein</td>\n",
       "      <td>B, L</td>\n",
       "      <td>6SF6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29634</th>\n",
       "      <td>PSPCHEKADCILERDGSRS</td>\n",
       "      <td>Protein</td>\n",
       "      <td>C, D</td>\n",
       "      <td>6SF6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29635</th>\n",
       "      <td>KVFGRCELAAAMKRHGLDNYRGYSLGNWVCAAKFESNFNTQATNRN...</td>\n",
       "      <td>Protein</td>\n",
       "      <td>A</td>\n",
       "      <td>6SET</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29636</th>\n",
       "      <td>KVFGRCELAAAMKRHGLDNYRGYSLGNWVCAAKFESNFNTQATNRN...</td>\n",
       "      <td>Protein</td>\n",
       "      <td>A</td>\n",
       "      <td>6SEW</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29637</th>\n",
       "      <td>VDTKEFLNHQVANLNVFTVKIHQIHWYMRGHNFFTLHEKMDDLYSE...</td>\n",
       "      <td>Protein</td>\n",
       "      <td>A, B, C, D, E, F</td>\n",
       "      <td>6SEV</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29638 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Sequence Entity Polymer Type  \\\n",
       "0      GSQMTRQARRLYVGNIPFGITEEAMMDFFNAQMRLGGLTQAPGNPV...             Protein   \n",
       "1      GSQMTRQARRLYVGNIPFGITEEAMMDFFNAQMRLGGLTQAPGNPV...             Protein   \n",
       "2      GSQMTRQARRLYVGNIPFGITEEAMMDFFNAQMRLGGLTQAPGNPV...             Protein   \n",
       "3      SLRSDLINALYDENQKYDVCGIISAEGKIYPLGSDTKVLSTIFELF...             Protein   \n",
       "4      MAVLAESELGSEAQRERRKRILDATMAIASKGGYEAVQMRAVADRA...             Protein   \n",
       "...                                                  ...                 ...   \n",
       "29633  DVLMTQIPLSLPVSLGDQASISCRSSQNIVHSNGNTYLEWYLQKPG...             Protein   \n",
       "29634                                PSPCHEKADCILERDGSRS             Protein   \n",
       "29635  KVFGRCELAAAMKRHGLDNYRGYSLGNWVCAAKFESNFNTQATNRN...             Protein   \n",
       "29636  KVFGRCELAAAMKRHGLDNYRGYSLGNWVCAAKFESNFNTQATNRN...             Protein   \n",
       "29637  VDTKEFLNHQVANLNVFTVKIHQIHWYMRGHNFFTLHEKMDDLYSE...             Protein   \n",
       "\n",
       "               Chain ID Entry Id (Polymer Entity Identifiers)  Unnamed: 4  \n",
       "0                     A                                  5EV3         NaN  \n",
       "1                     A                                  5EV2         NaN  \n",
       "2                     A                                  5EV4         NaN  \n",
       "3                  A, B                                  5F8A         NaN  \n",
       "4                  A, B                                  5FMP         NaN  \n",
       "...                 ...                                   ...         ...  \n",
       "29633              B, L                                  6SF6         NaN  \n",
       "29634              C, D                                  6SF6         NaN  \n",
       "29635                 A                                  6SET         NaN  \n",
       "29636                 A                                  6SEW         NaN  \n",
       "29637  A, B, C, D, E, F                                  6SEV         NaN  \n",
       "\n",
       "[29638 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_aa = pd.read_csv(\"aa_only.csv\")\n",
    "df_aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Where did the unnamed come from??\n",
    "unnamed = df_aa[\"Unnamed: 4\"] # Maybe trailing comma?\n",
    "unnamed.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding unique values in cloumn \"Entity Polymer Type\"\n",
    "I want to find unique values as described [here](https://chrisalbon.com/python/data_wrangling/pandas_list_unique_values_in_column/)\n",
    "\n",
    "This way I can be sure that my cleaning was successful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Protein'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding unique names in cols\n",
    "pol_type = df_aa['Entity Polymer Type']\n",
    "pol_type.unique() # I am now sure that all DNA and RNA and Protein/NA lines have been removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Sequence\",\"Entity Polymer Type\",\"Chain ID\",\"Entry Id (Polymer Entity Identifiers)\",\n",
      "\"GSQMTRQARRLYVGNIPFGITEEAMMDFFNAQMRLGGLTQAPGNPVLAVQINQDKNFAFLEFRSVDETTQAMAFDGIIFQGQSLKIRRPHDYQPLPGMSENPSVYVPGVVSTVVPDSAHKLFIGGLPNYLNDDQVKELLTSFGPLKAFNLVKDSATGLSKGYAFCEYVDINVTDQAIAGLNGMQLGDKKLLVQRASVGAKN\",\"Protein\",\"A\",\"5EV3\",\n",
      "\"GSQMTRQARRLYVGNIPFGITEEAMMDFFNAQMRLGGLTQAPGNPVLAVQINQDKNFAFLEFRSVDETTQAMAFDGIIFQGQSLKIRRPHDYQPLPGMSENPSVYVPGVVSTVVPDSAHKLFIGGLPNYLNDDQVKELLTSFGPLKAFNLVKDSATGLSKGYAFCEYVDINVTDQAIAGLNGMQLGDKKLLVQRASVGAKN\",\"Protein\",\"A\",\"5EV2\",\n"
     ]
    }
   ],
   "source": [
    "!head -3 aa_only.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sed '1d' aa_only.csv > noheader_aa_only.csv # removing header before generating fasta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   29639 aa_only.csv\n"
     ]
    }
   ],
   "source": [
    "!wc -l aa_only.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   29638 noheader_aa_only.csv\n"
     ]
    }
   ],
   "source": [
    "!wc -l noheader_aa_only.csv # value matches file is ok proceeding to make fasta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I want to consider the comma as a field sepparator \n",
    "\n",
    "Since there are several chains per entry denoted as e.g.:\n",
    "\n",
    "``` \"CAGTTTCAAACTC\",\"D, I\",\"5FD3\",```\n",
    "\n",
    "I need to remove the comma between the chains first and replace it with a space:\n",
    "*  ``` sed 's/\\, / /g' $i.csv ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Sequence\",\"Entity Polymer Type\",\"Chain ID\",\"Entry Id (Polymer Entity Identifiers)\",\n",
      "\"GSQMTRQARRLYVGNIPFGITEEAMMDFFNAQMRLGGLTQAPGNPVLAVQINQDKNFAFLEFRSVDETTQAMAFDGIIFQGQSLKIRRPHDYQPLPGMSENPSVYVPGVVSTVVPDSAHKLFIGGLPNYLNDDQVKELLTSFGPLKAFNLVKDSATGLSKGYAFCEYVDINVTDQAIAGLNGMQLGDKKLLVQRASVGAKN\",\"Protein\",\"A\",\"5EV3\",\n",
      "\"GSQMTRQARRLYVGNIPFGITEEAMMDFFNAQMRLGGLTQAPGNPVLAVQINQDKNFAFLEFRSVDETTQAMAFDGIIFQGQSLKIRRPHDYQPLPGMSENPSVYVPGVVSTVVPDSAHKLFIGGLPNYLNDDQVKELLTSFGPLKAFNLVKDSATGLSKGYAFCEYVDINVTDQAIAGLNGMQLGDKKLLVQRASVGAKN\",\"Protein\",\"A\",\"5EV2\",\n",
      "\"GSQMTRQARRLYVGNIPFGITEEAMMDFFNAQMRLGGLTQAPGNPVLAVQINQDKNFAFLEFRSVDETTQAMAFDGIIFQGQSLKIRRPHDYQPLPGMSENPSVYVPGVVSTVVPDSAHKLFIGGLPNYLNDDQVKELLTSFGPLKAFNLVKDSATGLSKGYAFCEYVDINVTDQAIAGLNGMQLGDKKLLVQRASVGAKN\",\"Protein\",\"A\",\"5EV4\",\n",
      "\"SLRSDLINALYDENQKYDVCGIISAEGKIYPLGSDTKVLSTIFELFSRPIINKIAEKHGYIVEEPKQQNHYPDFTLYKPSEPNKKIAIDIKTTYTNKENEKIKFTLGGYTSFIRNNTKNIVYPFDQYIAHWIIGYVYTRVATRKSSLKTYNINELNEIPKPYKGVKVFLQDKWVIAGDLAGSGNTTNIGSIHAHYKDFVEGKGIFDSEDEFLDYWRNYERTSQLRNDKYNNISEYRNWIYRGRK\",\"Protein\",\"AB\",\"5F8A\",\n",
      "\"MAVLAESELGSEAQRERRKRILDATMAIASKGGYEAVQMRAVADRADVAVGTLYRYFPSKVHLLVSALGREFSRIDAKTDRSAVAGATPFQRLNFMVGKLNRAMQRNPLLTEAMTRAYVFADASAASEVDQVEKLIDSMFARAMANGEPTEDQYHIARVISDVWLSNLLAWLTRRASATDVSKRLDLAVRLLIGDQDSAHHHHHH\",\"Protein\",\"AB\",\"5FMP\",\n",
      "\"GAASMDKKYSIGLAIGTNSVGWAVITDEYKVPSKKFKVLGNTDRHSIKKNLIGALLFDSGETAEATRLKRTARRRYTRRKNRICYLQEIFSNEMAKVDDSFFHRLEESFLVEEDKKHERHPIFGNIVDEVAYHEKYPTIYHLRKKLVDSTDKADLRLIYLALAHMIKFRGHFLIEGDLNPDNSDVDKLFIQLVQTYNQLFEENPINASGVDAKAILSARLSKSRRLENLIAQLPGEKKNGLFGNLIALSLGLTPNFKSNFDLAEDAKLQLSKDTYDDDLDNLLAQIGDQYADLFLAAKNLSDAILLSDILRVNTEITKAPLSASMIKRYDEHHQDLTLLKALVRQQLPEKYKEIFFDQSKNGYAGYIDGGASQEEFYKFIKPILEKMDGTEELLVKLNREDLLRKQRTFDNGSIPHQIHLGELHAILRRQEDFYPFLKDNREKIEKILTFRIPYYVGPLARGNSRFAWMTRKSEETITPWNFEEVVDKGASAQSFIERMTNFDKNLPNEKVLPKHSLLYEYFTVYNELTKVKYVTEGMRKPAFLSGEQKKAIVDLLFKTNRKVTVKQLKEDYFKKIECFDSVEISGVEDRFNASLGTYHDLLKIIKDKDFLDNEENEDILEDIVLTLTLFEDREMIEERLKTYAHLFDDKVMKQLKRRRYTGWGRLSRKLINGIRDKQSGKTILDFLKSDGFANRNFMQLIHDDSLTFKEDIQKAQVSGQGDSLHEHIANLAGSPAIKKGILQTVKVVDELVKVMGRHKPENIVIEMARENQTTQKGQKNSRERMKRIEEGIKELGSQILKEHPVENTQLQNEKLYLYYLQNGRDMYVDQELDINRLSDYDVDAIVPQSFLKDDSIDNKVLTRSDKNRGKSDNVPSEEVVKKMKNYWRQLLNAKLITQRKFDNLTKAERGGLSELDKAGFIKRQLVETRQITKHVAQILDSRMNTKYDENDKLIREVKVITLKSKLVSDFRKDFQFYKVREINNYHHAHDAYLNAVVGTALIKKYPKLESEFVYGDYKVYDVRKMIAKSEQEIGKATAKYFFYSNIMNFFKTEITLANGEIRKRPLIETNGETGEIVWDKGRDFATVRKVLSMPQVNIVKKTEVQTGGFSKESILPKRNSDKLIARKKDWDPKKYGGFDSPTVAYSVLVVAKVEKGKSKKLKSVKELLGITIMERSSFEKNPIDFLEAKGYKEVKKDLIIKLPKYSLFELENGRKRMLASAGELQKGNELALPSKYVNFLYLASHYEKLKGSPEDNEQKQLFVEQHKHYLDEIIEQISEFSKRVILADANLDKVLSAYNKHRDKPIREQAENIIHLFTLTNLGAPAAFKYFDTTIDRKRYTSTKEVLDATLIHQSITGLYETRIDLSQLGGD\",\"Protein\",\"B\",\"5FQ5\",\n",
      "\"MAPKCIECHINIEMDPVLHDVFKLQVCKQCSKEHPEKYALLTKTECKEDYFLTDPELNDEDLFHRLEKPNPHSGTFARMQLFVRCEVEAFAFKKWGGEEGLDEEWQRREEGKAHRREKKYGSAWSHPQFEK\",\"Protein\",\"AB\",\"5G32\",\n",
      "\"MAPKCIECHINIEMDPVLHDVFKLQVCKQCSKEHPEKYALLTKTECKEDYFLTDPELNDEDLFHRLEKPNPHSGTFARMQLFVRCEVEAFAFKKWGGEEGLDEEWQRREEGKAHRREKKYGSAWSHPQFEK\",\"Protein\",\"AB\",\"5G34\",\n",
      "\"MAPKCIECHINIEMDPVLHDVFKLQVCKQCSKEHPEKYALLTKTECKEDYFLTDPELNDEDLFHRLEKPNPHSGTFARMQLFVRCEVEAFAFKKWGGEEGLDEEWQRREEGKAHRREKKYGSAWSHPQFEK\",\"Protein\",\"AB\",\"5G33\",\n"
     ]
    }
   ],
   "source": [
    "# Removing commas between chains\n",
    "\n",
    "sed 's/\\, //g' aa_only.csv > nospace.csv\n",
    "\n",
    "head nospace.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generating the FASTA file\n",
    "\n",
    "* Using awk: defining the comma as field sepparator.\n",
    "\n",
    "* ``` awk -F ',' ```\n",
    "\n",
    "* filtering for lenght in the range of 50 - 300 \n",
    "\n",
    "*  ``` 'length($1) > 50 && length($1) < 301 {print \">\"$4\":\"$3\"\\n\"$1}' ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat nospace.csv | awk -F ',' 'length($1) > 50 && length($1) < 301 {print \">\"$4\":\"$3\"\\n\"$1}' | sed 's/\\\"//g' > 50_300.fasta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">5EV3:A\n",
      "GSQMTRQARRLYVGNIPFGITEEAMMDFFNAQMRLGGLTQAPGNPVLAVQINQDKNFAFLEFRSVDETTQAMAFDGIIFQGQSLKIRRPHDYQPLPGMSENPSVYVPGVVSTVVPDSAHKLFIGGLPNYLNDDQVKELLTSFGPLKAFNLVKDSATGLSKGYAFCEYVDINVTDQAIAGLNGMQLGDKKLLVQRASVGAKN\n",
      ">5EV2:A\n",
      "GSQMTRQARRLYVGNIPFGITEEAMMDFFNAQMRLGGLTQAPGNPVLAVQINQDKNFAFLEFRSVDETTQAMAFDGIIFQGQSLKIRRPHDYQPLPGMSENPSVYVPGVVSTVVPDSAHKLFIGGLPNYLNDDQVKELLTSFGPLKAFNLVKDSATGLSKGYAFCEYVDINVTDQAIAGLNGMQLGDKKLLVQRASVGAKN\n",
      ">5EV4:A\n",
      "GSQMTRQARRLYVGNIPFGITEEAMMDFFNAQMRLGGLTQAPGNPVLAVQINQDKNFAFLEFRSVDETTQAMAFDGIIFQGQSLKIRRPHDYQPLPGMSENPSVYVPGVVSTVVPDSAHKLFIGGLPNYLNDDQVKELLTSFGPLKAFNLVKDSATGLSKGYAFCEYVDINVTDQAIAGLNGMQLGDKKLLVQRASVGAKN\n",
      ">5F8A:AB\n",
      "SLRSDLINALYDENQKYDVCGIISAEGKIYPLGSDTKVLSTIFELFSRPIINKIAEKHGYIVEEPKQQNHYPDFTLYKPSEPNKKIAIDIKTTYTNKENEKIKFTLGGYTSFIRNNTKNIVYPFDQYIAHWIIGYVYTRVATRKSSLKTYNINELNEIPKPYKGVKVFLQDKWVIAGDLAGSGNTTNIGSIHAHYKDFVEGKGIFDSEDEFLDYWRNYERTSQLRNDKYNNISEYRNWIYRGRK\n",
      ">5FMP:AB\n",
      "MAVLAESELGSEAQRERRKRILDATMAIASKGGYEAVQMRAVADRADVAVGTLYRYFPSKVHLLVSALGREFSRIDAKTDRSAVAGATPFQRLNFMVGKLNRAMQRNPLLTEAMTRAYVFADASAASEVDQVEKLIDSMFARAMANGEPTEDQYHIARVISDVWLSNLLAWLTRRASATDVSKRLDLAVRLLIGDQDSAHHHHHH\n"
     ]
    }
   ],
   "source": [
    "head 50_300.fasta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sequences containing X need to be removed:\n",
    "\n",
    "Working on the script and testing it along the way. The final result is saved as\n",
    "\n",
    "#### removeX.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lines_to_list(filename):\n",
    "    ''' Reads all lines from a file and saves them to a list. '''\n",
    "    content_list = []\n",
    "    with open(filename, \"r\") as rfile:\n",
    "        content_list = rfile.readlines()\n",
    "        return content_list\n",
    "\n",
    "myfastalist = lines_to_list(\"50_300.fasta\")  #works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59276"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(myfastalist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29638\n",
      "29638\n",
      "59276\n"
     ]
    }
   ],
   "source": [
    "def split_list(liste):\n",
    "    ''' Splits a evennumbered list into two lists. id_list contains all odd items while seq_list contains all even items. Returns the two lists.'''\n",
    "    id_list = liste[::2]\n",
    "    seq_list = liste[1::2]\n",
    "    return id_list, seq_list\n",
    "\n",
    "# teste = ['a', 'b', 'c', 'd', 'e', 'f'] #Works\n",
    "ids, seq = split_list(myfastalist)\n",
    "\n",
    "\n",
    "print(len(ids))\n",
    "print(len(seq))\n",
    "print(len(myfastalist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_X(id1, seq2):\n",
    "    '''Removes items containing X in the sequence list but also the ID in the ID list. \n",
    "    Returns an ID list and an'''\n",
    "    noXid = []\n",
    "    noXseq = []\n",
    "    for i in range(len(id1)):\n",
    "        flag = \"X\" in seq2[i]\n",
    "        if flag == False:\n",
    "            noXid.append(id1[i])\n",
    "            noXseq.append(seq2[i])\n",
    "    return noXid, noXseq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28951\n",
      "28951\n"
     ]
    }
   ],
   "source": [
    "new_id, new_seq = remove_X(ids, seq)\n",
    "\n",
    "print(len(new_id))\n",
    "print(len(new_seq))\n",
    "\n",
    "def no_X_id_and_seq(id_list, seq_list):\n",
    "    ''' Joins the lists to a big list containing both id and sequences. Returns one big list'''\n",
    "    biglist = []\n",
    "    for i in range(len(id_list)):\n",
    "        biglist.append(id_list[i])\n",
    "        biglist.append(seq_list[i])\n",
    "    return biglist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57902"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biglist = no_X_id_and_seq(new_id, new_seq)\n",
    "len(biglist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Writing list to file:\n",
    "\n",
    "def list_to_fasta(liste):\n",
    "    '''Takes one id list and one sequlist as input. Writes all elements i to \n",
    "    a file. Returns the file.'''\n",
    "    with open('no_X.fasta', 'w') as F:\n",
    "        for i in liste:\n",
    "            F.write(str(i))\n",
    "    F.close            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_to_fasta(biglist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_short(infile, outfile):\n",
    "    del_seq_index = []\n",
    "    lines_list = []\n",
    "    with open(infile) as rfile:\n",
    "        lines_list = rfile.readlines()\n",
    "        for i in range(1, len(lines_list),2):\n",
    "            if len(lines_list[i]) < 7:\n",
    "                del_seq_index.append(i-1) # appending header index\n",
    "                del_seq_index.append(i)   # appending sequence index\n",
    "    with open(outfile, 'w') as wfile:\n",
    "        for i in range(len(lines_list)):\n",
    "            if i in del_seq_index:\n",
    "                continue\n",
    "            wfile.write(lines_list[i])    \n",
    "        \n",
    "filter_short(\"no_X.fasta\", 'longsequences.fasta')                   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Clustering the Sequences in blastclust\n",
    "\n",
    "Sending file to be clustered to the VM:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "scp no_X_long_sequs.fasta @proj:~/lb2-2020-project-englander\n",
    "\n",
    "screen\n",
    "\n",
    "source /opt/conda/bin/activate\n",
    "\n",
    "blastclust -i no_X_long_sequs.fasta -o final_clusters -S 30 -L 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Picking longest seuqence of each cluster: by default col1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cat final_clusters | awk $1 {print} > best_of_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in {1..5}\n",
    "do\n",
    "    mv $i.csv ./orignial_csv/$i.csv\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in {1..5}\n",
    "do\n",
    "     mv ${i}new.csv ./orignial_csv/${i}new.csv\n",
    "done     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Generating FASTA Containing ONLY Sequences of Best Cluster\n",
    "\n",
    "* I think the easiest is if I generate a list of best_of_final_cluster\n",
    "\n",
    "    - Need to first generate a new file that contains the \">\" character in front of every sequence\n",
    "\n",
    "\n",
    "* And generate a dictionary of the no_X_long_sequs.fasta   \n",
    "\n",
    "* Then I want to use the list to loop on the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making sure the output of the script will be fasta standard\n",
    "cat best_of_final_cluster | sed 's/^/>/' > crocodile_ids_final_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import sys\n",
    "\n",
    "def lines_to_list(infile1): \n",
    "    ''' Reads all lines from a file and saves them to a list. '''\n",
    "    content_list = []\n",
    "    with open(infile1, \"r\") as rfile:\n",
    "        content_list = rfile.readlines()\n",
    "        return content_list\n",
    "\n",
    "def split_list(infile1):\n",
    "    ''' Splits a evennumbered list into two lists. id_list contains \n",
    "    all odd items while seq_list contains all even items. Returns the two lists.'''\n",
    "    myfastalist = lines_to_list(infile1)  #works\n",
    "    id_list = myfastalist[::2]\n",
    "    seq_list = myfastalist[1::2]\n",
    "    return id_list, seq_list\n",
    "\n",
    "def dict_from_lists(infile1):\n",
    "    '''Takes feeds two lists into a dictionary. \n",
    "    Returns the dicitonary'''\n",
    "    id_list, seq_list = split_list(infile1)\n",
    "    keys = id_list\n",
    "    values = seq_list\n",
    "    full_dict = dict(zip(keys, values))\n",
    "    return full_dict\n",
    "    \n",
    "def keep_whats_in_dict(infile1, infile2, outfile):\n",
    "    '''Loops through a list and a dictionary. Appending the values\n",
    "    of the list (PDB ids which are also the keys of the dictionary) and the\n",
    "    values of the dictionary to the outfile.'''\n",
    "    idlist = lines_to_list(infile2) # reading ids from file into list\n",
    "    aa_dict = dict_from_lists(infile1)\n",
    "    with open(outfile, 'a') as afile:\n",
    "        for i in idlist:\n",
    "            afile.write(i) #appending ID in even lines\n",
    "            afile.write(aa_dict[i]) # appending value (sequ) in odd lines\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    infile1 = sys.argv[1]\n",
    "    infile2 = sys.argv[2]\n",
    "    outfile = sys.argv[3]\n",
    "    keep_whats_in_dict(infile1, infile2, outfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the script\n",
    "python  make_fasta_from_best_of_each_cluster.py no_X_long_sequs.fasta crocodile_ids_final_cluster crocodile_best_of_final_cluster.fasta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make_fasta_from_best_of_each_cluster.py       100% 1536    19.3KB/s   00:00    \n"
     ]
    }
   ],
   "source": [
    "scp -i ~/.ssh/id_rsa.pub ./make_fasta_from_best_of_each_cluster.py proj:~/lb2-2020-project-englander"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crocodile_best_of_final_cluster.fasta         100%  704KB   1.1MB/s   00:00    \n"
     ]
    }
   ],
   "source": [
    "scp -i ~/.ssh/id_rsa.pub ./crocodile_best_of_final_cluster.fasta proj:~/lb2-2020-project-englander"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Mergeing all fasta files of the jpred set \n",
    "\n",
    "Need it later to generate blastdb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat *.fasta > JPREDall.fasta  # merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    1348\n"
     ]
    }
   ],
   "source": [
    "grep \">\" JPREDall.fasta | wc -l  # works --> merged all 1348 files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JPREDall.fasta                                100%  226KB 777.5KB/s   00:00    \n"
     ]
    }
   ],
   "source": [
    "scp -i ~/.ssh/id_rsa.pub ./JPREDall.fasta proj:~/lb2-2020-project-englander"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "makeblastdb -in ./makeblastdb/JPREDall.fasta -dbtype prot\n",
    "\n",
    "Building a new DB, current time: 09/23/2020 14:29:12\n",
    "New DB name:   /home/um19/lb2-2020-project-englander/makeblastdb/JPREDall.fasta\n",
    "New DB title:  ./makeblastdb/JPREDall.fasta\n",
    "Sequence type: Protein\n",
    "Keep MBits: T\n",
    "Maximum file size: 1000000000B\n",
    "Adding sequences from FASTA; added 1348 sequences in 0.06898 seconds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Reducing Redundancy\n",
    "\n",
    "I want to produce a blind testset that is as dissimilar to the training set as possible.\n",
    "\n",
    "* Running blastp with blindset against JPRED training set\n",
    "* I dentifying all sequences in the blindset that have LESS than 30% seq ID with any other sequ in the training set.\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    " blastp -query ../crocodile_best_of_final_cluster.fasta -db JPREDall.fasta -evalue 0.01 -out hits.blastp.tab -outfmt 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hits.blastp.tab                               100%   43KB 177.0KB/s   00:00    \n"
     ]
    }
   ],
   "source": [
    "# copying hits.blast.tab to local\n",
    "scp -i ~/.ssh/um19_id_rsa um19@m19.lsb.biocomp.unibo.it:~/lb2-2020-project-englander/makeblastdb/hits.blastp.tab ~/01-Unibo/02_Lab2/project_blindset/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     759 hits.blastp.tab\n"
     ]
    }
   ],
   "source": [
    "wc -l hits.blastp.tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5MA4:A\td4duia_\t83.439\t157\t26\t0\t3\t159\t7\t163\t1.87e-86\t251\n",
      "5MA4:A\td4duia_\t77.444\t133\t29\t1\t165\t296\t31\t163\t5.71e-63\t191\n",
      "6D8X:A\td1fcya_\t29.032\t186\t126\t3\t109\t292\t53\t234\t1.41e-19\t80.5\n",
      "6G4T:A\td3k34a_\t56.757\t259\t111\t1\t7\t265\t1\t258\t2.30e-110\t314\n"
     ]
    }
   ],
   "source": [
    "head -4 hits.blastp.tab\n",
    "# $1 pdb_Id $2 jprd id $3 % identity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Non-Redundant Set With Least Similarty \n",
    "\n",
    "Step 3 from the Slides: \"Filter out from the preliminary chain set, all chains having at least one BLAST hit with SI >= 30% with any sequence in the JPRED4 dataset\n",
    "\n",
    "### Generating 2 Files Containing Only Relevant Lines\n",
    "\n",
    "file above30:\n",
    "* I'll extract ```$1``` if ``` $3 > 30 ```\n",
    "\n",
    "file below30\n",
    "* I have to extract ```$1``` if col ```$3 < 30 ```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# awk keep filed if col 3 < 30 pipe to new file.\n",
    "awk -F ' ' '$3 < 30 {print $1 \" \" $3}' hits.blastp.tab > below_30.hits\n",
    "awk -F ' ' '$3 >= 30 {print $1 \" \" $3}' hits.blastp.tab > above_30.hits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Keeping IDs only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "awk -F ' ' '$3 < 30 {print $1}' hits.blastp.tab > id_below_30.hits\n",
    "awk -F ' ' '$3 >= 30 {print $1}' hits.blastp.tab > id_above_30.hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lines_to_list(infile1): \n",
    "    ''' Reads all lines from a file and saves them to a list. '''\n",
    "    content_list = []\n",
    "    with open(infile1, \"r\") as rfile:\n",
    "        content_list = rfile.readlines()\n",
    "        return content_list\n",
    "        \n",
    "below = lines_to_list(\"id_below_30.hits\")  # list of all ids scoring below 30% id\n",
    "above = lines_to_list('id_above_30.hits')  # list of all ids scoring above and equal to 30% id\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187\n",
      "572\n"
     ]
    }
   ],
   "source": [
    "print(len(below))\n",
    "print(len(above))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177\n"
     ]
    }
   ],
   "source": [
    "# \"6D8X:A\\n\" in above\n",
    "# head -30 id_below_30.hits > ids_test\n",
    "# head -30 id_above_30.hits > ids_above_test\n",
    "\n",
    "def remove_matches(lower, higher):\n",
    "    '''Takes two lists as input and returns a list that contains\n",
    "    all values of 'lower' values that are NOT element of 'higher'.'''\n",
    "    keepers = []          # list holding all ids that have not scored >= 30% with any of the JPRED sequnces\n",
    "    for i in lower:       \n",
    "        if i not in higher: \n",
    "            keepers.append(i)  # keeps only ids that are not reported in the list \"above\"\n",
    "    return keepers\n",
    "\n",
    "keep = remove_matches(below, above) \n",
    "\n",
    "print(len(keep))\n",
    "# Have 177 unique sequnces with no match above 30% id with any other sequ in the testing (JPRED) set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3920\n"
     ]
    }
   ],
   "source": [
    "all_ids = lines_to_list(\"best_of_final_cluster\") # generating list of all ids that were in the blastp input\n",
    "print(len(all_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3398"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def keep_mis_matches(biglist, partiallist):\n",
    "    '''Stores exclusively biglist values that are not reported in partiallist.\n",
    "    Returns the biglist with all partiallist matches removed. Keeps all values \n",
    "    that donot match any element of partiallist in a new list. Returns the new list.'''\n",
    "    keepers = []\n",
    "    for i in biglist:\n",
    "        if i not in partiallist:\n",
    "            keepers.append(i) \n",
    "    return keepers\n",
    "\n",
    "all_without_above = keep_mis_matches(all_ids, above)\n",
    "len(all_without_above)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_list_to_file(liste, newfile):\n",
    "    '''Takes as input a list and writes each element to a new file'''\n",
    "    with open(newfile, 'a') as afile: \n",
    "        for i in liste:\n",
    "            afile.write(i)\n",
    "            \n",
    "write_list_to_file(all_without_above, 'try_again')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_scoring_below30.py\n",
    "\n",
    "# input of blastp = fastafile find missing\n",
    "\n",
    "# interseciton of set below() and above() --> throw_away\n",
    "# find and remove throw away id file\n",
    "\n",
    "# make list of all ids reproted in fastinputblastp\n",
    "# turn fastinputblastp_list into fastinputblastp_set (biggest set)\n",
    "# fastinputblastp_set - above_set \n",
    "\n",
    "def lines_to_list(infile1): \n",
    "    ''' Reads all lines from a file and saves them to a list. '''\n",
    "    content_list = []\n",
    "    with open(infile1, \"r\") as rfile:\n",
    "        content_list = rfile.readlines()\n",
    "        return content_list\n",
    "        \n",
    "below = lines_to_list(\"id_below_30.hits\")  # list of all ids scoring below 30% id\n",
    "above = lines_to_list('id_above_30.hits')  # list of all ids scoring above and equal to 30% id\n",
    "\n",
    "def remove_matches(lower, higher):\n",
    "    '''Takes two lists as input and returns a list that contains\n",
    "    all values of 'lower' values that are NOT element of 'higher'.'''\n",
    "    keepers = []          # list holding all ids that have not scored >= 30% with any of the JPRED sequnces\n",
    "    for i in lower:       \n",
    "        if i not in higher: \n",
    "            keepers.append(i)  # keeps only ids that are not reported in the list \"above\"\n",
    "    return keepers\n",
    "\n",
    "keep = remove_matches(below, above) \n",
    "\n",
    "# print(len(keep))\n",
    "# Have 177 unique sequnces with no match above 30% id with any other sequ in the testing (JPRED) set.\n",
    "\n",
    "##########################################################\n",
    "# Making a list of all ids (input IDs of the blastp)\n",
    "##########################################################\n",
    "\n",
    "all_ids = lines_to_list(\"best_of_final_cluster\") # generating list of all ids that were in the blastp input\n",
    "# print(len(all_ids))\n",
    "\n",
    "def keep_mis_matches(biglist, partiallist):\n",
    "    '''Stores exclusively biglist values that are not reported in partiallist.\n",
    "    Returns the biglist with all partiallist matches removed. Keeps all values \n",
    "    that donot match any element of partiallist in a new list. Returns the new list.'''\n",
    "    keepers = []\n",
    "    for i in biglist:\n",
    "        if i not in partiallist:\n",
    "            keepers.append(i) \n",
    "    return keepers\n",
    "\n",
    "all_without_above = keep_mis_matches(all_ids, above)\n",
    "# len(all_without_above)\n",
    "\n",
    "def write_list_to_file(liste, newfile):\n",
    "    '''Takes as input a list and writes each element to a new file'''\n",
    "    with open(newfile, 'a') as afile: \n",
    "        for i in liste:\n",
    "            afile.write(i)\n",
    "            \n",
    "write_list_to_file(all_without_above, 'try_again')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Randomly Sort and Pick 150 Sequences \n",
    "\n",
    "Sometimes not all IDS have an associated PDB file thus I select 160 to be sure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     160 random.blindset2\n"
     ]
    }
   ],
   "source": [
    "!cat ids_0-30 | sort -R | head -160 > random.blindset2 # in case some PDB files are not available\n",
    "!wc -l random.blindset2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that I still have *NOT* removed identical chain IDs:\n",
    "\n",
    "* The file still contains all letters denoting different chains after the \":\"\n",
    "\n",
    "* printing it to a new file only keeping first letter after the \":\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5U39:A\n",
      "6R82:AB\n",
      "6G3Z:AB\n",
      "5XJL:2\n",
      "6EHA:AB\n",
      "6NTV:ABC\n",
      "6T8S:AAABBBCCC\n",
      "4YWN:AB\n",
      "5FLY:AB\n",
      "5JVV:AB\n"
     ]
    }
   ],
   "source": [
    "!tail random.blindset2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat random.blindset2 | cut -c-6 > id_and_chain_blindset2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking if really no above 30 are in the new list\n",
    "def lines_to_list(infile1): \n",
    "    ''' Reads all lines from a file and saves them to a list. '''\n",
    "    content_list = []\n",
    "    with open(infile1, \"r\") as rfile:\n",
    "        content_list = rfile.readlines()\n",
    "        return content_list\n",
    "        \n",
    "bigset = lines_to_list(\"random.blindset2\")  # list of all ids scoring below 30% id\n",
    "above = lines_to_list('id_above_30.hits')  # list of all ids scoring above and equal to 30% id\n",
    "\n",
    "def remove_matches(l1, l2):\n",
    "    '''Takes two lists as input and returns a list that contains\n",
    "    all values of 'lower' values that are NOT element of 'higher'.'''\n",
    "    keepers = []          # list holding all ids that have not scored >= 30% with any of the JPRED sequnces\n",
    "    for i in l1:       \n",
    "        if i not in l2: \n",
    "            keepers.append(i)  # keeps only ids that are not reported in the list \"above\"\n",
    "    return keepers\n",
    "\n",
    "keep = remove_matches(bigset, above) \n",
    "len(keep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Download Structures from PDB\n",
    "\n",
    "For each of the 150 sequences I have to download the pdb structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat random.blindset2 | cut -c-4 > only_id_blindset2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in\n",
    "# https://files.rcsb.org/view/6OZJ.pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Generate DSSP files from selected PDB files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['6LTZ', '6EXX', '5XGA', '5WUJ', '4ZY7', '5F2A', '5D1R', '5UNI', '5U7E', '5ANP', '6HKS', '6J0Y', '6L77', '6KKO', '6GW6', '5LDD', '6K7Q', '4Y0L', '5GNA', '5C8A', '4ZC4', '6EI6', '5UMV', '6OR3', '5U4U', '5XKS', '5GHL', '5XYF', '5N07', '5FB9', '5CEG', '7BWF', '4YTE', '5V0M', '4Y4O', '6SE1', '5UC0', '5WNW', '5IHF', '5T2Y', '5IB0', '6USC', '4UIQ', '4YBB', '6YJ1', '6DHX', '5D6T', '6DN4', '5BP5', '6ISU', '6FSF', '5VOG', '5IR2', '5D71', '5BPX', '5II0', '4Y0O', '5AUN', '5C5Z', '5KWV', '6MDW', '5FQ0', '7BVV', '5AV5', '5FFL', '6OOD', '5KQA', '5DCF', '5GKE', '5ZRY', '5UIV', '4Y4O', '6GBI', '5MC9', '6FWT', '6HSV', '6HFG', '5A88', '5YEI', '6NDR', '5KLC', '6MAB', '6AOZ', '5T2X', '5LTF', '6J19', '6T7O', '6MLX', '5YMX', '7JTL', '5K21', '5CTD', '6R5W', '5EIV', '5HT8', '5DD8', '5D16', '4ZEY', '6VCI', '5Y7W', '4ZLR', '5XVK', '6VK4', '6IA7', '5HJF', '6QLC', '6WK3', '5WOQ', '5YSN', '5Z1N', '5BPU', '5ABR', '4ZKP', '6ON1', '6I9L', '5AZW', '6KOK', '5Y4R', '5CYB', '5A6W', '5U5N', '5BN2', '6UXF', '6K6L', '5WD6', '6OVI', '5V2I', '6IQO', '6MD3', '5JSN', '5JWO', '6Q7N', '5NL9', '6Q8J', '5WD8', '6CEQ', '5BPK', '5BXQ', '6OKM', '5MMH', '6H9E', '5F1S', '6SLK', '5DG6', '5DQ0', '5X4B', '5B71', '4ZRZ', '5M9O', '6DEW', '5U39', '6R82', '6G3Z', '5XJL', '6EHA', '6NTV', '6T8S', '4YWN', '5FLY', '5JVV']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "160"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lines_to_list(infile1): \n",
    "    ''' Reads all lines from a file and saves them to a list. '''\n",
    "    content_list = []\n",
    "    with open(infile1, \"r\") as rfile:\n",
    "        content_list = rfile.readlines()\n",
    "        return content_list\n",
    "        \n",
    "bigset = lines_to_list(\"only_id_blindset2\") # Contain trailing newline char\n",
    "#removing \\n :\n",
    "def rstrip_each_item(list):\n",
    "    my_150_PDB = []\n",
    "    for i in list:\n",
    "        clean = i.rstrip()\n",
    "        my_150_PDB.append(clean)\n",
    "    return my_150_PDB\n",
    "\n",
    "my_150_PDB = rstrip_each_item(bigset)\n",
    "print(my_150_PDB)\n",
    "len(my_150_PDB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Bio\n",
    "# from Bio.PDB import PDBList\n",
    "# '''Selecting structures from PDB'''\n",
    "# pdbl = PDBList()\n",
    "# PDBlist2= my_150_PDB\n",
    "# for i in PDBlist2:\n",
    "#     pdbl.retrieve_pdb_file(i,pdir='PDB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sed: illegal option -- z\n",
      "usage: sed script [-Ealn] [-i extension] [file ...]\n",
      "       sed [-Ealn] [-i extension] [-e script] ... [-f script_file] ... [file ...]\n"
     ]
    }
   ],
   "source": [
    "!cat only_id_blindset2 | sed -z 's/\\n/, /g' > commas2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd blindset_all_PDBs/150_blind_PDBs/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in {1..150}\n",
    "do\n",
    "    gunzip *ent.gz\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Generating DSSP files from all 150 PDB files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "# Running the DSSP on the extracted PDB files\n",
    "for i in *.ent\n",
    "do\n",
    "        mkdssp -i \"$i\" -o \"./dsspout/$i.dssp\"\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting chain and secondary structure from DSSP files:\n",
    "\n",
    "* protein chain: ```$3```\n",
    "* Secondary Structure Summanry ```$4```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd /Users/ila/01-Unibo/02_Lab2/project_blindset/blindset_all_PDBs/150_blind_PDBs/dssp_back/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ila/01-Unibo/02_Lab2/project_blindset\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">4uiq: chain??????\n",
      "DPAKTLEAVSAVADWLRDPQRESPARAQLAEAVRLTARTLAAVAPGASVEVRVPPFVAVQCISGPKHTRGTPPNVVETDARTWLLLATGLLDIADAGASVQMSGSRAAEVAHWLPVVRI\n",
      "The three classes:\n",
      "CHHHHHHHHHCCHHHHHCCCCCCCCHHHHHHHHHHHHHHHHHHCCCCCEEEEECCCEEEEECCCCCCCCCCCCEEEEECHHHHHHHHHCCCCHHHCHHHEEEECCCHHHHHHHCCCCCC\n"
     ]
    }
   ],
   "source": [
    "# dict holding all possbible 8 SSconformations (keys)\n",
    "# values are the desired classes that need to be mapped out.\n",
    "structure_dict = {\"H\":\"H\", \"G\":\"H\", \"I\":\"H\", \"B\":\"E\", \"E\":\"E\", \"T\":\"C\", \"S\":\"C\", \" \":\"C\"} \n",
    "\n",
    "# try to print only lines after  # \n",
    "#  RESIDUE AA STRUCTURE BP1 BP2  ACC     N-H-->O    O-->H-N    N-H-->O    O-->H-N    TCO  KAPPA ALPHA  PHI   PSI    X-CA   Y-CA   Z-CA \n",
    "\n",
    "\n",
    "def lines_list(fname):\n",
    "    with open(fname) as ofile:\n",
    "        flist = ofile.readlines() # returns list containing each line of the file\n",
    "        return flist\n",
    "\n",
    "def relevant_lines(liste, desired_chain):\n",
    "    relevant = False # boolean variable ###################################################################\n",
    "#     desired_chain = \"A\" # change to load from id_and_chain_blindset2\n",
    "    raw_ccstring = ''  ####################################################################################\n",
    "    three_classes = ''\n",
    "    aa_string = ''\n",
    "    for line in liste:\n",
    "        if '#' in line: # find last line before relevant output\n",
    "            relevant =True   # flips rel to true - so the folowing lines are saved\n",
    "            continue\n",
    "        if relevant:\n",
    "            if line[11] == desired_chain:\n",
    "                raw_ccstring += line[16]\n",
    "                aa_string += line[13]           \n",
    "    return raw_ccstring, aa_string\n",
    "\n",
    "def raw_to_threclasses(rawstring):\n",
    "        threeclasses = ''\n",
    "        for letter in rawstring:\n",
    "                threeclasses += structure_dict[letter]\n",
    "        return threeclasses\n",
    "\n",
    "id_chain = lines_list('id_and_chain_blindset2')\n",
    "\n",
    "for id in id_chain:\n",
    "    fields_lists = id.split(':') # list contains ID and chain\n",
    "    fname = \"pdb\"+fields_lists[0].lower()+\".ent.dssp\"\n",
    "    chain = fields_lists[1]\n",
    "    \n",
    "    \n",
    "mylist = lines_list(\"/Users/ila/01-Unibo/02_Lab2/project_blindset/blindset_all_PDBs/150_blind_PDBs/dssp_back/pdb4zy7.ent.dssp\")\n",
    "raw, aa = relevant_lines(mylist)\n",
    "\n",
    "three_class_string = raw_to_threclasses(raw)\n",
    "\n",
    "print('>4uiq: chain??????')\n",
    "print(aa)\n",
    "print('The three classes:')\n",
    "print(three_class_string)\n",
    "\n",
    "# read file and \n",
    "# 4Y4O:14 \n",
    "# 4Y4O:18 \n",
    "# 5XJL:2\n",
    "\n",
    "# id_and_chain_blindset2 contains all the IDs and corresponding chains\n",
    "# need to wirte a script that\n",
    "# takes id_and chain as input (list) and adds them to the header of each corresponding protein\n",
    "# pdb input file\n",
    "# Program needs to use desired chain as input from that file too\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " scp -i ~/.ssh/id_rsa.pub ./150_blind_PDBs/* proj:~/lb2-2020-project-englander/150_blind_PDBs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Desired Chain From Each DSSP file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id_and_chain_blindset2\n"
     ]
    }
   ],
   "source": [
    "!ls id_and_chain_blindset2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6LTZ:A\n",
      "6EXX:A\n",
      "5XGA:A\n",
      "5WUJ:B\n",
      "4ZY7:A\n",
      "5F2A:A\n",
      "5D1R:A\n",
      "5UNI:A\n",
      "5U7E:A\n",
      "5ANP:A\n",
      "6HKS:A\n",
      "6J0Y:C\n",
      "6L77:A\n",
      "6KKO:A\n",
      "6GW6:B\n",
      "5LDD:B\n",
      "6K7Q:A\n",
      "4Y0L:A\n",
      "5GNA:B\n",
      "5C8A:A\n",
      "4ZC4:A\n",
      "6EI6:A\n",
      "5UMV:A\n",
      "6OR3:A\n",
      "5U4U:A\n",
      "5XKS:A\n",
      "5GHL:A\n",
      "5XYF:A\n",
      "5N07:A\n",
      "5FB9:A\n",
      "5CEG:A\n",
      "7BWF:B\n",
      "4YTE:A\n",
      "5V0M:A\n",
      "4Y4O:14\n",
      "6SE1:A\n",
      "5UC0:A\n",
      "5WNW:A\n",
      "5IHF:A\n",
      "5T2Y:A\n",
      "5IB0:A\n",
      "6USC:A\n",
      "4UIQ:A\n",
      "4YBB:C\n",
      "6YJ1:A\n",
      "6DHX:A\n",
      "5D6T:A\n",
      "6DN4:A\n",
      "5BP5:C\n",
      "6ISU:A\n",
      "6FSF:A\n",
      "5VOG:A\n",
      "5IR2:A\n",
      "5D71:A\n",
      "5BPX:A\n",
      "5II0:A\n",
      "4Y0O:A\n",
      "5AUN:A\n",
      "5C5Z:A\n",
      "5KWV:A\n",
      "6MDW:A\n",
      "5FQ0:A\n",
      "7BVV:A\n",
      "5AV5:A\n",
      "5FFL:A\n",
      "6OOD:A\n",
      "5KQA:A\n",
      "5DCF:A\n",
      "5GKE:A\n",
      "5ZRY:A\n",
      "5UIV:A\n",
      "4Y4O:18\n",
      "6GBI:A\n",
      "5MC9:B\n",
      "6FWT:A\n",
      "6HSV:A\n",
      "6HFG:B\n",
      "5A88:A\n",
      "5YEI:B\n",
      "6NDR:A\n",
      "5KLC:A\n",
      "6MAB:A\n",
      "6AOZ:A\n",
      "5T2X:A\n",
      "5LTF:A\n",
      "6J19:B\n",
      "6T7O:A\n",
      "6MLX:A\n",
      "5YMX:A\n",
      "7JTL:A\n",
      "5K21:A\n",
      "5CTD:C\n",
      "6R5W:A\n",
      "5EIV:A\n",
      "5HT8:A\n",
      "5DD8:A\n",
      "5D16:A\n",
      "4ZEY:A\n",
      "6VCI:A\n",
      "5Y7W:A\n",
      "4ZLR:A\n",
      "5XVK:A\n",
      "6VK4:D\n",
      "6IA7:A\n",
      "5HJF:A\n",
      "6QLC:A\n",
      "6WK3:A\n",
      "5WOQ:A\n",
      "5YSN:B\n",
      "5Z1N:A\n",
      "5BPU:A\n",
      "5ABR:A\n",
      "4ZKP:A\n",
      "6ON1:A\n",
      "6I9L:A\n",
      "5AZW:A\n",
      "6KOK:A\n",
      "5Y4R:C\n",
      "5CYB:A\n",
      "5A6W:C\n",
      "5U5N:A\n",
      "5BN2:A\n",
      "6UXF:A\n",
      "6K6L:A\n",
      "5WD6:A\n",
      "6OVI:A\n",
      "5V2I:A\n",
      "6IQO:A\n",
      "6MD3:A\n",
      "5JSN:B\n",
      "5JWO:A\n",
      "6Q7N:A\n",
      "5NL9:A\n",
      "6Q8J:A\n",
      "5WD8:A\n",
      "6CEQ:A\n",
      "5BPK:C\n",
      "5BXQ:A\n",
      "6OKM:R\n",
      "5MMH:A\n",
      "6H9E:A\n",
      "5F1S:A\n",
      "6SLK:B\n",
      "5DG6:A\n",
      "5DQ0:A\n",
      "5X4B:A\n",
      "5B71:E\n",
      "4ZRZ:A\n",
      "5M9O:A\n",
      "6DEW:A\n",
      "5U39:A\n",
      "6R82:A\n",
      "6G3Z:A\n",
      "5XJL:2\n",
      "6EHA:A\n",
      "6NTV:A\n",
      "6T8S:A\n",
      "4YWN:A\n",
      "5FLY:A\n",
      "5JVV:A\n"
     ]
    }
   ],
   "source": [
    "!cat id_and_chain_blindset2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
